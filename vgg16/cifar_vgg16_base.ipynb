{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85389c8a-ccab-4598-92e4-59826a46c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ad3645-3bb9-4389-a8de-cbcfc7597879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f56ab8-f985-4178-a461-3e3dc2419e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size = 32\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=1)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc273ab4-2914-4fdf-83ba-8d140e05803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "__all__ = [\n",
    "    'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n",
    "    'vgg19_bn', 'vgg19',\n",
    "]\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    '''\n",
    "    VGG model \n",
    "    '''\n",
    "    def __init__(self, features):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "         # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', \n",
    "          512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "def vgg11():\n",
    "    \"\"\"VGG 11-layer model (configuration \"A\")\"\"\"\n",
    "    return VGG(make_layers(cfg['A']))\n",
    "\n",
    "\n",
    "def vgg11_bn():\n",
    "    \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\"\"\"\n",
    "    return VGG(make_layers(cfg['A'], batch_norm=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f089f56-09ee-4963-a482-b6818b9a0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = vgg11()\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01ca8aa4-139d-45f2-b6ca-3cdea24d2de9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1563] loss: 2670.1061990261\n",
      "Accuracy of the network on the 10000 test images: 49.26 %\n",
      "27.0536949634552\n",
      "[2,  1563] loss: 1889.5529642105\n",
      "Accuracy of the network on the 10000 test images: 61.69 %\n",
      "53.36817789077759\n",
      "[3,  1563] loss: 1475.3501022458\n",
      "Accuracy of the network on the 10000 test images: 68.83 %\n",
      "79.86519527435303\n",
      "[4,  1563] loss: 1180.1710777283\n",
      "Accuracy of the network on the 10000 test images: 72.33 %\n",
      "105.95502972602844\n",
      "[5,  1563] loss: 946.6317785978\n",
      "Accuracy of the network on the 10000 test images: 72.49 %\n",
      "131.84630823135376\n",
      "[6,  1563] loss: 734.3494693562\n",
      "Accuracy of the network on the 10000 test images: 74.17 %\n",
      "158.1043996810913\n",
      "[7,  1563] loss: 553.4420631267\n",
      "Accuracy of the network on the 10000 test images: 76.54 %\n",
      "184.25185680389404\n",
      "[8,  1563] loss: 413.1512109768\n",
      "Accuracy of the network on the 10000 test images: 74.9 %\n",
      "210.36726808547974\n",
      "[9,  1563] loss: 308.6411533263\n",
      "Accuracy of the network on the 10000 test images: 76.41 %\n",
      "236.41137838363647\n",
      "[10,  1563] loss: 242.1998377917\n",
      "Accuracy of the network on the 10000 test images: 75.67 %\n",
      "262.7813894748688\n",
      "[11,  1563] loss: 195.2411487519\n",
      "Accuracy of the network on the 10000 test images: 73.2 %\n",
      "289.1160726547241\n",
      "[12,  1563] loss: 167.3189197729\n",
      "Accuracy of the network on the 10000 test images: 76.0 %\n",
      "315.06199049949646\n",
      "[13,  1563] loss: 144.2861403894\n",
      "Accuracy of the network on the 10000 test images: 75.44 %\n",
      "341.15268301963806\n",
      "[14,  1563] loss: 128.4303872394\n",
      "Accuracy of the network on the 10000 test images: 75.77 %\n",
      "367.0138564109802\n",
      "[15,  1563] loss: 122.1822132941\n",
      "Accuracy of the network on the 10000 test images: 76.77 %\n",
      "393.202050447464\n",
      "Finished Training\n",
      "393.2024760246277\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = []\n",
    "\n",
    "for epoch in range(15):  # loop over the dataset multiple times\n",
    "    count=0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        count=i\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # print statistics\n",
    "\n",
    "    print(f'[{epoch + 1}, {count + 1:5d}] loss: {running_loss  :.10f}')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')   \n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    results += [[epoch,end-start,running_loss,100*correct/total]]\n",
    "    running_loss = 0.0\n",
    "print('Finished Training')\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb79f5c-5210-42e4-92d8-28a7b42891bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_results = np.asarray(results)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3,figsize=(15,5),dpi=120)\n",
    "fig.suptitle('VGG16 with Convolution and a sequence of Non-Linear Layers')\n",
    "ax1.plot(main_results[:,0], main_results[:,1])\n",
    "ax1.set_title(\"Runtime\")\n",
    "ax2.plot(main_results[:,0], main_results[:,2])\n",
    "ax2.set_title(\"Loss metric\")\n",
    "ax2.set_xlabel('Epochs', fontsize=16)\n",
    "ax3.plot(main_results[:,0], main_results[:,3])\n",
    "ax3.set_title(\"Accuracy on test\")\n",
    "\n",
    "np.savetxt(\"../results_vgg16_base.csv\", main_results, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58128bd-dd17-4ac3-a911-a91559872ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
